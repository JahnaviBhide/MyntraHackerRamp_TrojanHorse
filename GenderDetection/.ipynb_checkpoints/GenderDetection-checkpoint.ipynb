{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2826e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682d43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_width = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "831bba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52102c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = './dataset/'\n",
    "file = 'man1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ceba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_net = cv2.dnn.readNetFromCaffe(path + 'deploy.prototxt.txt', path + 'res10_300x300_ssd_iter_140000_fp16.caffemodel')\n",
    "gender_net = cv2.dnn.readNetFromCaffe(path + 'deploy_gender.prototxt', path + 'gender_net.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd472e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "GENDER_LIST = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc8d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaces(frame, confidence_threshold=0.5):\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n",
    "    face_net.setInput(blob)\n",
    "    output = np.squeeze(face_net.forward())\n",
    "    faces = []\n",
    "    for i in range(output.shape[0]):\n",
    "        confidence = output[i, 2]\n",
    "        if confidence > confidence_threshold:\n",
    "            box = output[i, 3:7] * \\\n",
    "                np.array([frame.shape[1], frame.shape[0],\n",
    "                         frame.shape[1], frame.shape[0]])\n",
    "            start_x, start_y, end_x, end_y = box.astype(np.int64)\n",
    "            start_x, start_y, end_x, end_y = start_x - \\\n",
    "                10, start_y - 10, end_x + 10, end_y + 10\n",
    "            start_x = 0 if start_x < 0 else start_x\n",
    "            start_y = 0 if start_y < 0 else start_y\n",
    "            end_x = 0 if end_x < 0 else end_x\n",
    "            end_y = 0 if end_y < 0 else end_y\n",
    "            faces.append((start_x, start_y, end_x, end_y))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fbf94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOptimalFontScale(text, width):\n",
    "    for scale in reversed(range(0, 60, 1)):\n",
    "        textSize = cv2.getTextSize(text, fontFace=cv2.FONT_HERSHEY_DUPLEX, fontScale=scale/10, thickness=1)\n",
    "        new_width = textSize[0][0]\n",
    "        if (new_width <= width):\n",
    "            return scale/10\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05690a08",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VAISHN~1\\AppData\\Local\\Temp/ipykernel_8060/1428549065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(path + file)\n",
    "frame = img.copy()\n",
    "flag = 0\n",
    "width = frame_width\n",
    "height = None\n",
    "if frame.shape[1] > frame_width:\n",
    "    dim = None\n",
    "    (h, w) = img.shape[:2]\n",
    "    if width is None and height is None:\n",
    "        flag = 1 \n",
    "        frame = img\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    if(flag != 1):\n",
    "        frame = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "faces = getFaces(frame)\n",
    "for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        blob = cv2.dnn.blobFromImage(image=face_img, scalefactor=1.0, size=(\n",
    "            227, 227), mean=MODEL_MEAN_VALUES, swapRB=False, crop=False)\n",
    "        gender_net.setInput(blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        i = gender_preds[0].argmax()\n",
    "        gender = GENDER_LIST[i]\n",
    "        gender_confidence_score = gender_preds[0][i]\n",
    "    \n",
    "        label = \"{}-{:.2f}%\".format(gender, gender_confidence_score*100)\n",
    "        print(label)\n",
    "        yPos = start_y - 15\n",
    "        while yPos < 15:\n",
    "            yPos += 15\n",
    "        optimal_font_scale = getOptimalFontScale(label,((end_x-start_x)+25))\n",
    "        box_color = (255, 0, 0) if gender == \"Male\" else (147, 20, 255)\n",
    "        cv2.rectangle(frame, (start_x, start_y), (end_x, end_y), box_color, 2)\n",
    "        cv2.putText(frame, label, (start_x, yPos),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, optimal_font_scale, box_color, 2)\n",
    "\n",
    "cv2.imshow('Gender Predictor', frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bb807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e256ba86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
